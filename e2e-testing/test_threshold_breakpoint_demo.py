#!/usr/bin/env python3
"""
Threshold Breakpoint Demo - Shows content that passes 0.8 but fails 0.95
"""

from ai_quality_validation import AIQualityValidator

def test_threshold_breakpoint():
    """Test content that's right at the threshold breakpoint"""
    print("🎯 Threshold Breakpoint Demo")
    print("=" * 40)
    print("Testing content that should pass 0.8 but fail 0.95")
    print()
    
    # Content that's similar but not identical - should be around 0.9 similarity
    test_content = """Daily Brief - 2024-01-15

Email Summary:
• Quarterly Sales Report - john@company.com
• Client Meeting Request - sarah@client.com
• Invoice Payment Overdue - billing@vendor.com

Key Insights:
• 3 urgent items require immediate attention
• 2 client meetings scheduled for this week
• 1 invoice payment overdue
• New project proposal received

Action Items:
• Review quarterly sales report
• Schedule follow-up meeting with client
• Process invoice payment
• Prepare project proposal

Generated by Person.ai"""

    print("📝 Test content:")
    print(f"   Length: {len(test_content)} chars")
    print(f"   Preview: {test_content[:80]}...")
    
    # Test with multiple thresholds to find the breakpoint
    thresholds = [0.7, 0.8, 0.85, 0.9, 0.95, 0.98]
    
    print(f"\n🧪 Testing with multiple thresholds:")
    print(f"{'Threshold':<10} {'Score':<8} {'Passed':<8} {'Status'}")
    print("-" * 45)
    
    for threshold in thresholds:
        # Create custom validator with specific threshold
        class CustomValidator(AIQualityValidator):
            def _validate_semantic_similarity(self, content: str, content_type: str):
                baseline_key = f"{content_type}_baseline"
                if baseline_key not in self.baselines:
                    return {"score": 0.0, "passed": False, "details": "No baseline available"}
                
                baseline = self.baselines[baseline_key]
                similarity = self._calculate_similarity(content, baseline["content"])
                
                passed = similarity >= threshold
                
                return {
                    "score": similarity,
                    "passed": passed,
                    "details": f"Similarity: {similarity:.3f} (threshold: {threshold})",
                    "similarity": similarity,
                    "baseline_created": baseline["created_at"]
                }
        
        validator = CustomValidator()
        result = validator.validate_content_quality(test_content, "text")
        
        score = result['validations']['semantic_similarity']['score']
        passed = result['validations']['semantic_similarity']['passed']
        
        status = "✅ PASS" if passed else "❌ FAIL"
        print(f"{threshold:<10} {score:<8.3f} {str(passed):<8} {status}")
    
    print(f"\n🎯 Key Demo Points:")
    print(f"• Same content tested against different thresholds")
    print(f"• Shows how threshold affects validation results")
    print(f"• Demonstrates the breakpoint between pass/fail")
    print(f"• Higher thresholds = stricter validation")

if __name__ == "__main__":
    test_threshold_breakpoint()
